---
title: 'NLP workshop - Exploring Presidential Debate on twitter'
author: "Daniel S. Hain (dsh@business.aau.dk)"
date: "Updated `r format(Sys.time(), '%B %d, %Y')`"
output:
  html_notebook:
    code_folding: show
    df_print: paged
    toc: true
    toc_depth: 2
    toc_float:
      collapsed: false
    theme: flatly
---

```{r setup, include=FALSE}
### Generic preamble
rm(list=ls())
Sys.setenv(LANG = "en") # For english language
options(scipen = 5) # To deactivate annoying scientific number notation

### Knitr options
library(knitr) # For display of the markdown
knitr::opts_chunk$set(warning=FALSE,
                     message=FALSE,
                     comment=FALSE, 
                     fig.align="center"
                     )
```

```{r}
### Load standardpackages
library(tidyverse) # Collection of all the good stuff like dplyr, ggplot2 ect.
library(magrittr) # For extra-piping operators (eg. %<>%)
```

```{r}
library(tidytext)
```


# Download the data

```{r}
# download and open some Trump tweets from trump_tweet_data_archive
library(jsonlite)
tmp <- tempfile()
download.file("https://github.com/SDS-AAU/SDS-master/raw/master/M2/data/pol_tweets.gz", tmp)

tweets_raw <- stream_in(gzfile(tmp, "pol_tweets"))
```

```{r}
# download and open some Trump tweets from trump_tweet_data_archive
tmp1 <- tempfile()
download.file("https://github.com/SDS-AAU/SDS-master/raw/master/M2/data/pres_debate_2020.gz", tmp1)

tweets_raw1 <- stream_in(gzfile(tmp1, "pres_debate_2020"))
```

```{r}
tweets_raw %>% glimpse()
```

```{r}
tweets <- tibble(ID = colnames(tweets_raw[[1]]), 
                 text = tweets_raw[[1]] %>% as.character(), 
                 labels = tweets_raw[[2]] %>% as.logical())
tweets1 <- tibble(ID = colnames(tweets_raw1[[1]]), 
                 text = tweets_raw1[[1]] %>% as.character(), 
                 labels = tweets_raw1[[2]] %>% as.logical())
#rm(tweets_raw)
```

```{r}
tweets %>% glimpse()
tweets1 %>% glimpse()
```

```{r}
tweets %<>%
  filter(!(text %>% str_detect('^RT'))) # Filter retweets
tweets1 %<>%
  filter(!(text %>% str_detect('^RT'))) # Filter retweets
```


#Tidying

```{r}
tweets_tidy = tweets %>% 
  unnest_tokens(word, text, token = "tweets")
```

```{r}
tweets_tidy %>%  head(50)
```

```{r}
tweets_tidy %>% count(word, sort = TRUE)
```

# Preprocessing

```{r}

```

